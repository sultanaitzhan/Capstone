% Preamble
\documentclass[10pt,reqno,oneside,a4paper, landscape]{article}
\usepackage[a4paper,includeheadfoot,left=25mm,right=25mm,top=00mm,bottom=20mm,headheight=20mm]{geometry}
\usepackage{siunitx}
\input{texHead}
\author{Sultan Aitzhan}
\title{Report 3}
\newcommand{\theshorttitle}{Report 3}
\date{\today}
\allowdisplaybreaks

\begin{document}
\maketitle
\thispagestyle{fancy}
\tableofcontents


\section{Time stepping and finite differences: the whole line}

Recall the equation we obtained for the surface elevation on the whole line:
\begin{equation}\label{srfcexp}
\eta_{tt} = \eta_{xx} + \mu^2\left( \frac{1}{3} \eta_{xxxx} + \eta_{xt} \int^{x}_{-\infty} \eta_t \D x' + \eta^2_x + \eta^2_t +\eta \eta_{xx} + \partial_x^2 \left(\int^{x}_{-\infty} \eta_t \D x' \right)^2 \right).
\end{equation}
To do time stepping, introduce
\begin{equation}\label{Uexp}
u = \eta_t.
\end{equation}
Also, note that 
\[ 
\partial_x^2 \left(\int^{x}_{-\infty} \eta_t \D x' \right)^2 = 2(\eta_t^2 + \eta_{tx} \int^x_{-\infty}\eta_t \D x')
\]
Then, combining \eqref{Uexp} and \eqref{srfcexp}, we obtain a two-dimensional system:
\begin{equation}\label{systemeq1}
  \partial_t \begin{bmatrix} u \\ \eta \end{bmatrix} =
  \begin{bmatrix} 
  \mu^2\left(2 u_{x} \int^{x}_{-\infty} u \D x' +2 u^2 \right) + \eta_{xx} + \mu^2 \left( \frac{1}{3} \eta_{xxxx} + \eta^2_x + \eta\eta_{xx} \right) \\
  u \end{bmatrix}.
\end{equation}
Now, consider \eqref{srfcexp} on a finite interval $[a,b],$ and let partition the interval into $n+1$ points $\{ x_k\}^n_{k=0},$ with $x_0 = a$ and $x_n = b.$ This means that the integral terms becomes
\[ 
\int^{x}_{-\infty} \eta_t \D x' = \Bigg\{\int^{a}_{-\infty} + \int^x_a \Bigg\} \eta_t \D x' \approx \int^x_a \eta_t \D x', 
\]
while assuming that 
\[ \int^{a}_{-\infty}  \eta_t \D x' \]
is small enough. Now, we employ forward Euler time stepping. First, observe that
\begin{align*}
u_t(x_k, t_j) &= \frac{u(x_k, t_{j+1}) - u(x_k, t_j)}{\DT} = f_1(\eta, u, t) &&\implies u(x_k, t_{j+1}) = u(x_k, t_j) + \DT f_1(\eta, u, t) \\
\eta_t(x_k, t_j) &= \frac{\eta(x_k, t_{j+1}) - \eta(x_k, t_j)}{\DT} = f_2(\eta, u, t) &&\implies \eta(x_k, t_{j+1}) =  \eta(x_k, t_j)+ \DT f_2(\eta, u, t), 
\end{align*}
where 
\begin{align*}
f_1(\eta, u, t) &= \eta_{xx} + \mu^2 \left( 2 u_{x} \int^{x}_{-\infty} u \D x' +2 u^2 + \frac{1}{3} \eta_{xxxx} + \eta^2_x + \eta\eta_{xx} \right) \\
f_2(\eta, u, t) &= u(x_k, t_j).
\end{align*}
Observe that the highest order derivative is 4, so we need to use five-point stencils. In particular, we use five point midpoint stencil for $x_2, \ldots, x_{n-2},$ and five point, one-sided stencils at $x_0, x_1, x_{n-1}, x_n.$ First, consider the system for $x_2, \ldots, x_{n-2}:$
\begin{align*}
f_1(\eta(x_k, t_j), u(x_k, t_j), t) &= \eta(x_k, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_k, t_j)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_k, t_j)_{x} \int^{x_k}_{x_0} u \D x' +2 u(x_k, t_j)^2 + \eta(x_k, t_j)^2_x + \eta(x_k, t_j)\eta(x_k, t_j)_{xx} \right),
\end{align*}
where we have separated the linear and nonlinear terms.
Let $\DX = x_k - x_{k-1}$ and recall the finite difference formulas at $x:$
\begin{align*}
f'(x)&= \frac{f(x- 2\DX ) - 8 f(x-\DX) + 8f(x+ \DX) - f(x+2\DX) }{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
f''(x)&= \frac{-f(x- 2\DX ) +16 f(x-\DX) - 30f+16f(x+ \DX) - f(x+2\DX)}{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
f''''(x)&= \frac{f(x- 2\DX ) -4 f(x-\DX) + 6f - 4f(x+ \DX) + f(x+2\DX)}{(\Delta x)^4} + \mathcal{O}((\Delta x)^2)
\end{align*}
so that 
\begin{align*}
(\eta_k)_x&= \frac{\eta_{k-2} - 8 \eta_{k-1} + 8\eta_{k+1} - \eta_{k+2}}{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
(u_k)_x&= \frac{u_{k-2} - 8 u_{k-1} + 8u_{k+1} - u_{k+2} }{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
(\eta_k)_{xx} &= \frac{-\eta_{k-2} +16 \eta_{k-1} - 30\eta_k+16\eta_{k+1} - \eta_{k+2}}{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
(\eta_k)_{xxxx} &= \frac{\eta_{k-2} -4 \eta_{k-1} + 6\eta_k - 4\eta_{k+1} + \eta_{k+2}}{(\Delta x)^4} + \mathcal{O}((\Delta x)^2),
\end{align*}
where it is assumed $t = t_j.$ Also, by trapezoidal rule, 
\[ 
\int^{x_k}_{x_0} u \D x' = \sum_{i=0}^{n-1} \int^{x_{i+1}}_{x_{i}} u \D x = \frac{\DX}{2} \sum_{i=0}^{n-1} u(x_i) + u(x_{i+1}).
\]
At $x = x_0,$ we have 
\begin{align*}
f'(x)&= \frac{-25f(x) +48 f(x+\DX) -36f(x+ 2\DX) +16f(x+3\DX) - 3f(x+4\DX) }{12\DX} + \mathcal{O}((\Delta x)^4) \\
f''(x)&= \frac{35f(x)- 104 f(x+\DX) + 114 f(x+ 2\DX) - 56f(x+3\DX) + 11f(x+4\DX) }{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
f''''(x)&= \frac{f(x) -4 f(x+\DX) + 6f (x+2\DX)- 4f(x+ 3\DX) + f(x+4\DX)}{(\Delta x)^4} + \mathcal{O}((\Delta x)^2),
\end{align*}
so that 
\begin{align*}
(\eta_0)_x &= \frac{-25\eta_0 +48 \eta_{1} -36\eta_2+16\eta_3 - 3\eta_4}{12\DX} \\
(u_0)_x &= \frac{-25u_0 +48 u_{1} -36u_2+16u_3 - 3u_4}{12\DX} \\
(\eta_0)_{xx} &= \frac{35\eta_0 -104 \eta_{1} +114 \eta_2 -56\eta_3 + 11\eta_4}{12\DX^2} \\
(\eta_0)_{xxxx} &= \frac{\eta_0 -4 \eta_{1} +6 \eta_2 -4\eta_3 + \eta_4}{\DX^4}
\end{align*}
At $x= x_1,$ we have 
\begin{align*}
f'(x)&= \frac{-3f(x-\DX) -10 f(x) +18f(x+ \DX) -6f(x+2\DX) + f(x+3\DX) }{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
f''(x)&= \frac{11f(x-\DX) -20 f(x) +6f(x+ \DX) +4f(x+2\DX) - f(x+3\DX)}{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
f''''(x)&= \frac{f(x-\DX) -4 f(x) +6f(x+ \DX) -4f(x+2\DX) + f(x+3\DX)}{(\Delta x)^4} + \mathcal{O}((\Delta x)^2),
\end{align*}
so that 
\begin{align*}
(\eta_1)_x &= \frac{-3\eta_0 -10 \eta_{1} + 18 \eta_2 -6 \eta_3 + \eta_4}{12\DX} \\
(u_1)_x &= \frac{-3u_0 - 10 u_{1} + 18 u_2 - 6 u_3 + u_4}{12\DX} \\
(\eta_1)_{xx} &= \frac{11\eta_0 -20 \eta_{1} +6 \eta_2 + 4\eta_3 - \eta_4}{12\DX^2} \\
(\eta_1)_{xxxx} &= \frac{\eta_0 -4 \eta_{1} +6 \eta_2 -4\eta_3 + \eta_4}{\DX^4}
\end{align*}
At $x= x_{n-1},$ we have
\begin{align*}
f'(x)&= \frac{-f(x-3\DX) +6 f(x- 2\DX) -18f(x- \DX) +10f(x) + 3f(x+\DX) }{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
f''(x)&= \frac{-f(x-3\DX) +4 f(x- 2\DX) +6(x- \DX) -20 f(x) + 11 f(x+\DX) }{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
f''''(x)&= \frac{f(x-3\DX) -4 f(x- 2\DX) +6f(x- \DX) -4f(x) + f(x+\DX) }{(\Delta x)^4} + \mathcal{O}((\Delta x)^2),
\end{align*}
so that
\begin{align*}
(\eta_{n-1})_x &= \frac{-\eta_{n-4} + 6 \eta_{n-3} - 18 \eta_{n-2} +10 \eta_{n-1} + 3\eta_n}{12\DX} \\
(u_{n-1})_x &= \frac{-u_{n-4} + 6 u_{n-3} - 18 u_{n-2} +10 u_{n-1} + 3u_n}{12\DX} \\
(\eta_{n-1})_{xx} &= \frac{-\eta_{n-4} + 4 \eta_{n-3} + 6 \eta_{n-2} -20 \eta_{n-1} + 11\eta_n}{12\DX^2} \\
(\eta_{n-1})_{xxxx} &= \frac{\eta_{n-4} -4 \eta_{n-3} +6 \eta_{n-2} -4 \eta_{n-1} + \eta_n}{\DX^4}
\end{align*}
At $x= x_{n},$ we have
\begin{align*}
f'(x)&= \frac{f(x-4\DX)-4f(x-3\DX) +6 f(x- 2\DX) -4f(x- \DX) +f(x)}{12\Delta x} + \mathcal{O}((\Delta x)^4) \\
f''(x)&= \frac{11f(x-4\DX)-56f(x-3\DX) +114 f(x- 2\DX) -104f(x- \DX) +35f(x)}{12(\Delta x)^2} + \mathcal{O}((\Delta x)^2) \\
f''''(x)&= \frac{f(x-4\DX)-4f(x-3\DX) +6 f(x- 2\DX) -4f(x- \DX) +f(x)}{(\Delta x)^4} + \mathcal{O}((\Delta x)^2),
\end{align*}
so that 
\begin{align*} 
(\eta_{n})_x &= \frac{3\eta_{n-4} - 16 \eta_{n-3} + 36 \eta_{n-2} - 48  \eta_{n-1} + 25\eta_n}{12\DX} \\
(u_{n})_x &= \frac{3u_{n-4} - 16 u_{n-3} +3 6 u_{n-2} -48 u_{n-1} + 25 u_n}{12\DX} \\
(\eta_{n})_{xx} &= \frac{11\eta_{n-4} -56 \eta_{n-3} + 114 \eta_{n-2} -104 \eta_{n-1} + 35\eta_n}{12\DX^2} \\
(\eta_{n})_{xxxx} &= \frac{\eta_{n-4} -4 \eta_{n-3} +6 \eta_{n-2} -4 \eta_{n-1} + \eta_n}{\DX^4}.
\end{align*}
All in all, we obtain:
\begin{align*} f_1(\eta(x_0, t_j), u(x_0, t_j), t) &= \eta(x_0, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_0, t_j)_{xxxx} + \mu^2 \left(2 u(x_0, t_j)^2 + \eta(x_0, t_j)^2_x + \eta(x_0, t_j)\eta(x_0, t_j)_{xx} \right), \\
f_1(\eta(x_1, t_j), u(x_1, t_j), t) &= \eta(x_1, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_1, t_j)_{xxxx} \\
&+ \mu^2 \left(2 u(x_1, t_j)_{x} \int^{x_1}_{x_0} u \D x' + 2 u(x_1, t_j)^2 + \eta(x_1, t_j)^2_x + \eta(x_1, t_j)\eta(x_1, t_j)_{xx} \right), \\
f_1(\eta(x_2, t_j), u(x_2, t_j), t) &= \eta(x_2, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_2, t_j)_{xxxx} \\
&+ \mu^2 \left(2 u(x_2, t_j)_{x} \int^{x_2}_{x_0} u \D x' + 2 u(x_2, t_j)^2 + \eta(x_2, t_j)^2_x + \eta(x_2, t_j)\eta(x_2, t_j)_{xx} \right), \\
&\ldots \\
f_1(\eta(x_k, t_j), u(x_k, t_j), t) &= \eta(x_k, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_k, t_j)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_k, t_j)_{x} \int^{x_k}_{x_0} u \D x' +2 u(x_k, t_j)^2 + \eta(x_k, t_j)^2_x + \eta(x_k, t_j)\eta(x_k, t_j)_{xx} \right), \\
&\ldots \\
f_1(\eta(x_{n-1}, t_j), u(x_{n-1}, t_j), t) &= \eta(x_{n-1}, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_{n-1}, t_j)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_{n-1}, t_j)_{x} \int^{x_{n-1}}_{x_0} u \D x' +2 u(x_{n-1}, t_j)^2 + \eta(x_{n-1}, t_j)^2_x + \eta(x_{n-1}, t_j)\eta(x_{n-1}, t_j)_{xx} \right), \\
f_1(\eta(x_{n}, t_j), u(x_{n}, t_j), t) &= \eta(x_{n}, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_{n}, t_j)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_{n}, t_j)_{x} \int^{x_{n}}_{x_0} u \D x' +2 u(x_{n}, t_j)^2 + \eta(x_{n}, t_j)^2_x + \eta(x_{n}, t_j)\eta(x_{n}, t_j)_{xx} \right),
\end{align*}
Now, we obtain the discretised problem. First, consider the column of linear terms:
\begin{align*}
(\eta_0)_{xx} &+ \frac{\mu^2}{3} (\eta_0)_{xxxx}  \\
&= \frac{35\eta_0 -104 \eta_{1} +114 \eta_2 -56\eta_3 + 11\eta_4}{12\DX^2} + \frac{\mu^2}{3} \frac{\eta_0 -4 \eta_{1} +6 \eta_2 -4\eta_3 + \eta_4}{\DX^4} \\
&= \frac{35\DX^2 + 4 \mu^2}{12\DX^4} \eta_0 - \frac{104 \DX^2 + 16\mu^2}{12\DX^4} \eta_1 + \frac{114 \DX^2 + 24 \mu^2}{12\DX^4} \eta_2 - \frac{56 \DX^2 + 16\mu^2}{12\DX^4} \eta_3 + \frac{11 \DX^2 + 4\mu^2}{12\DX^4} \eta_4 \\
(\eta_1)_{xx} &+ \frac{\mu^2}{3} (\eta_1)_{xxxx} \\
&= \frac{11\eta_0 -20 \eta_{1} +6 \eta_2 + 4\eta_3 - \eta_4}{12\DX^2} +\frac{\mu^2}{3} \frac{\eta_0 -4 \eta_{1} +6 \eta_2 -4\eta_3 + \eta_4}{\DX^4} \\
&= \frac{11\DX^2 + 4 \mu^2}{12\DX^4} \eta_0 - \frac{20 \DX^2 + 16\mu^2}{12\DX^4} \eta_1 + \frac{6 \DX^2 + 24 \mu^2}{12\DX^4} \eta_2 + \frac{4 \DX^2 - 16\mu^2}{12\DX^4} \eta_3 + \frac{- \DX^2 + 4\mu^2}{12\DX^4} \eta_4 \\
&\ldots \\
(\eta_k)_{xx} &+ \frac{\mu^2}{3} (\eta_k)_{xxxx} \\
&= \frac{-\eta_{k-2} +16 \eta_{k-1} - 30\eta_k+16\eta_{k+1} - \eta_{k+2}}{12(\Delta x)^2} + 
\frac{\mu^2}{3} \frac{\eta_{k-2} -4 \eta_{k-1} + 6\eta_k - 4\eta_{k+1} + \eta_{k+2}}{(\Delta x)^4}\\
&=\frac{-\DX^2 + 4 \mu^2}{12\DX^4} \eta_{k-2} + \frac{16 (\DX^2 -\mu^2)}{12\DX^4} \eta_{k-1} + \frac{-30\DX^2 + 24 \mu^2}{12\DX^4} \eta_k - \frac{16(\DX^2 - \mu^2)}{12\DX^4} \eta_{k+1} + \frac{- \DX^2 + 4\mu^2}{12\DX^4} \eta_{k+2} \\
&\ldots \\
(\eta_{n-1})_{xx} &+ \frac{\mu^2}{3} (\eta_{n-1})_{xxxx} \\
&= \frac{-\eta_{n-4} + 4 \eta_{n-3} + 6 \eta_{n-2} -20 \eta_{n-1} + 11\eta_n}{12\DX^2}  + \frac{\mu^2}{3} \frac{\eta_{n-4} -4 \eta_{n-3} +6 \eta_{n-2} -4 \eta_{n-1} + \eta_n}{\DX^4} \\
&= \frac{-\DX^2 + 4 \mu^2}{12\DX^4} \eta_{n-4} + \frac{4 \DX^2 -16\mu^2}{12\DX^4} \eta_{n-3} + \frac{6\DX^2 + 24 \mu^2}{12\DX^4} \eta_{n-2} - \frac{20\DX^2 +16 \mu^2}{12\DX^4} \eta_{n-1} + \frac{11 \DX^2 + 4\mu^2}{12\DX^4} \eta_n \\
(\eta_{n})_{xx} &+ \frac{\mu^2}{3} (\eta_{n})_{xxxx} \\
&= 
\frac{11\eta_{n-4} -56 \eta_{n-3} + 114 \eta_{n-2} -104 \eta_{n-1} + 35\eta_n}{12\DX^2} + \frac{\mu^2}{3}\frac{\eta_{n-4} -4 \eta_{n-3} +6 \eta_{n-2} -4 \eta_{n-1} + \eta_n}{\DX^4} \\
&= \frac{11\DX^2 + 4 \mu^2}{12\DX^4} \eta_{n-4} - \frac{56 \DX^2 +16\mu^2)}{12\DX^4} \eta_{n-3} + \frac{114\DX^2 + 24 \mu^2}{12\DX^4} \eta_{n-2} - \frac{104\DX^2 +16 \mu^2}{12\DX^4} \eta_{n-1} + \frac{35 \DX^2 + 4\mu^2}{12\DX^4} \eta_n.
\end{align*}
Then, the matrix becomes
\begin{align*}
&\begin{bmatrix}
(\eta_0)_{xx} + \frac{\mu^2}{3} (\eta_0)_{xxxx} \\
(\eta_1)_{xx} + \frac{\mu^2}{3} (\eta_1)_{xxxx} \\
(\eta_2)_{xx} + \frac{\mu^2}{3} (\eta_2)_{xxxx} \\
\vdots \\
(\eta_k)_{xx} + \frac{\mu^2}{3} (\eta_k)_{xxxx} \\
\vdots \\
(\eta_{n-2})_{xx} + \frac{\mu^2}{3} (\eta_{n-2})_{xxxx} \\
(\eta_{n-1})_{xx} + \frac{\mu^2}{3} (\eta_{n-1})_{xxxx} \\
(\eta_{n})_{xx} + \frac{\mu^2}{3} (\eta_{n})_{xxxx}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{35\DX^2 + 4 \mu^2}{12\DX^4} & - \frac{104 \DX^2 + 16\mu^2}{12\DX^4} & \frac{114 \DX^2 + 24 \mu^2}{12\DX^4} & - \frac{56 \DX^2 + 16\mu^2}{12\DX^4} & \frac{11 \DX^2 + 4\mu^2}{12\DX^4} & 0 & 0 & 0 & \ldots \\
\frac{11\DX^2 + 4 \mu^2}{12\DX^4} & - \frac{20 \DX^2 + 16\mu^2}{12\DX^4} & \frac{6 \DX^2 + 24 \mu^2}{12\DX^4} & - \frac{4 \DX^2 - 16\mu^2}{12\DX^4} & \frac{- \DX^2 + 4\mu^2}{12\DX^4} & 0 & 0 & 0 & \ldots\\
\frac{-\DX^2 + 4 \mu^2}{12\DX^4} & \frac{16 (\DX^2 -\mu^2)}{12\DX^4} & \frac{-30\DX^2 + 24 \mu^2}{12\DX^4} & - \frac{16(\DX^2 - \mu^2)}{12\DX^4} & \frac{- \DX^2 + 4\mu^2}{12\DX^4} & 0 & 0 & 0 & \ldots \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots &\vdots & \vdots & \ldots \\
0 & \ldots & 0 & \frac{-\DX^2 + 4 \mu^2}{12\DX^4} & \frac{16 (\DX^2 -\mu^2)}{12\DX^4} & \frac{-30\DX^2 + 24 \mu^2}{12\DX^4} & - \frac{16(\DX^2 - \mu^2)}{12\DX^4} & \frac{- \DX^2 + 4\mu^2}{12\DX^4} & \ldots & 0 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots &\vdots & \vdots & \ldots \\
\ldots & 0 & 0 & 0 & \frac{-\DX^2 + 4 \mu^2}{12\DX^4} & \frac{16 (\DX^2 -\mu^2)}{12\DX^4} & \frac{-30\DX^2 + 24 \mu^2}{12\DX^4} & - \frac{16(\DX^2 - \mu^2)}{12\DX^4} & \frac{- \DX^2 + 4\mu^2}{12\DX^4}  \\
\ldots & 0 & 0 & 0 & -\frac{\DX^2 + 4 \mu^2}{12\DX^4} & \frac{4 \DX^2 -16\mu^2)}{12\DX^4} & \frac{6\DX^2 + 24 \mu^2}{12\DX^4} & \frac{-20\DX^2 -16 \mu^2}{12\DX^4} & \frac{11 \DX^2 + 4\mu^2}{12\DX^4} \\
\ldots & 0 & 0 & 0 & \frac{11\DX^2 + 4 \mu^2}{12\DX^4} & - \frac{56 \DX^2 +16\mu^2)}{12\DX^4} & \frac{114\DX^2 + 24 \mu^2}{12\DX^4} &- \frac{104\DX^2 +16 \mu^2}{12\DX^4} & \frac{35 \DX^2 + 4\mu^2}{12\DX^4} 
\end{bmatrix}
\begin{bmatrix}
\eta_0 \\
\eta_1 \\
\eta_2 \\
\vdots \\
\eta_k \\
\vdots \\
\eta_{n-2} \\
\eta_{n-1} \\
\eta_{n}
\end{bmatrix}
\end{align*}
For simplicity, let $\mathcal{A}$ represent the above matrix. Now, recall the system:
\begin{align*}
u(x_k, t_{j+1}) &= u(x_k, t_j) + \DT f_1(\eta(x_k, t_j), u(x_k, t_j), t), \\
\eta(x_k, t_{j+1}) &=  \eta(x_k, t_j)+ \DT u(x_k, t_j),
\end{align*}
where 
\begin{align*}
f_1(\eta(x_k, t_j), u(x_k, t_j), t) &= \eta(x_k, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_k, t_j)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_k, t_j)_{x} \int^{x_k}_{x_0} u \D x' +2 u(x_k, t_j)^2 + \eta(x_k, t_j)^2_x + \eta(x_k, t_j)\eta(x_k, t_j)_{xx} \right).
\end{align*}
For convenience, let 
\[ B_k = \left( 2 u(x_k, t_j)_{x} \int^{x_k}_{x_0} u \D x' +2 u(x_k, t_j)^2 + \eta(x_k, t_j)^2_x + \eta(x_k, t_j)\eta(x_k, t_j)_{xx} \right), 
\]
Let $\mathcal{B}$ represent the column vector of $B_k$'s. Then, we can write the system 
\begin{align*}
u(x_0, t_{j+1}) &= u(x_0, t_j) + \DT f_1(\eta(x_0, t_j), u(x_0, t_j), t) \\
u(x_1, t_{j+1}) &= u(x_1, t_j) + \DT f_1(\eta(x_1, t_j), u(x_1, t_j), t) \\
u(x_2, t_{j+1}) &= u(x_2, t_j) + \DT f_1(\eta(x_2, t_j), u(x_2, t_j), t) \\
&\vdots \\
u(x_{n-2}, t_{j+1}) &= u(x_{n-2}, t_j) + \DT f_1(\eta(x_{n-2}, t_j), u(x_{n-2}, t_j), t) \\
u(x_{n-1}, t_{j+1}) &= u(x_{n-1}, t_j) + \DT f_1(\eta(x_{n-1}, t_j), u(x_{n-1}, t_j), t) \\
u(x_n, t_{j+1}) &= u(x_n, t_j) + \DT f_1(\eta(x_n, t_j), u(x_n, t_j), t) \\
\end{align*}
as follows:
\begin{align*}
\begin{bmatrix}
u(x_0, t_{j+1}) \\
u(x_1, t_{j+1}) \\
u(x_2, t_{j+1}) \\
\vdots \\
u(x_{n-2}, t_{j+1}) \\
u(x_{n-1}, t_{j+1}) \\
u(x_n, t_{j+1}) 
\end{bmatrix} 
&= 
\begin{bmatrix}
u(x_0, t_{j}) \\
u(x_1, t_{j}) \\
u(x_2, t_{j}) \\
\vdots \\
u(x_{n-2}, t_{j}) \\
u(x_{n-1}, t_{j}) \\
u(x_n, t_{j}) 
\end{bmatrix} 
+ \DT 
\begin{bmatrix}
f_1(\eta(x_0, t_j), u(x_0, t_j), t)\\
f_1(\eta(x_1, t_j), u(x_1, t_j), t) \\
 f_1(\eta(x_2, t_j), u(x_2, t_j), t) \\
\vdots \\
f_1(\eta(x_{n-2}, t_j), u(x_{n-2}, t_j), t)\\
f_1(\eta(x_{n-1}, t_j), u(x_{n-1}, t_j), t) \\
f_1(\eta(x_n, t_j), u(x_n, t_j), t) 
\end{bmatrix} \\
&= 
\begin{bmatrix}
u(x_0, t_{j}) \\
u(x_1, t_{j}) \\
u(x_2, t_{j}) \\
\vdots \\
u(x_{n-2}, t_{j}) \\
u(x_{n-1}, t_{j}) \\
u(x_n, t_{j}) 
\end{bmatrix} 
+ \DT \mathcal{A} \begin{bmatrix}
\eta_0 \\
\eta_1 \\
\eta_2 \\
\vdots \\
\eta_{n-2} \\
\eta_{n-1} \\
\eta_{n}
\end{bmatrix}
+ \DT \mathcal{B}
\end{align*}
Now, let us see how one would perform time-stepping. As such, impose initial conditions 
\[ 
\eta(x, t_0) = f(x), \qquad u(x, t_0) = \eta_t(x, t_0) = g(x).
\]
Let $j = 0,$ and for simplicity, pick $k\in [0,n].$ The system is 
\begin{align*}
u(x_k, t_1) &= u(x_k, t_0) + \DT f_1(\eta(x_k, t_0), u(x_k, t_0)), \\
\eta(x_k, t_1) &=  \eta(x_k, t_0)+ \DT u(x_k, t_0),
\end{align*}
where 
\begin{align*}
f_1(\eta(x_k, t_0), u(x_k, t_0)) &= \eta(x_k, t_0)_{xx} + \frac{\mu^2}{3} \eta(x_k, t_0)_{xxxx} \\
&+ \mu^2 \left( 2 u(x_k, t_0)_{x} \int^{x_k}_{x_0} u \D x' +2 u(x_k, t_0)^2 + \eta(x_k, t_0)^2_x + \eta(x_k, t_0)\eta(x_k, t_0)_{xx} \right) \\
&= \frac{-\eta(x_{k-2}, t_0) +16 \eta(x_{k-1},t_0) - 30\eta(x_k, t_0)+16\eta(x_{k+1},t_0) - \eta(x_{k+2},t_0)}{12(\Delta x)^2} \\
&+ \frac{\mu^2}{3} \frac{\eta(x_{k-2},t_0) -4 \eta(x_{k-1},t_0) + 6\eta(x_k,t_0) - 4\eta(x_{k+1},t_0) + \eta(x_{k+2},t_0)}{(\Delta x)^4} \\
&+ \mu^2 \left( 2 u(x_k, t_0)_{x} \int^{x_k}_{x_0} u(x', t_0) \D x' +2 u(x_k, t_0)^2 + \eta(x_k, t_0)^2_x + \eta(x_k, t_0)\eta(x_k, t_0)_{xx} \right)
\end{align*}
Note that all the terms on the last line can be computed via finite differences and both initial conditions. With this, we obtain the values of $u, \eta$ at point $x_k$ and time $t_1.$ Performing this calculation for all $k,$ we move on to compute $u, \eta$ at time $t_2,$ and so on.  

\section{The half line problem}
In this section, we deal with this term 
\[ 
\partial_x(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ \partial_t \left( \eta \int^{x}_0\eta_{t} \D x' \right)\} \}
\]
More generally, we have the following result:
\begin{thm}
For nice enough $f$ defined on $x\geq 0,$ we have
\[ 
(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \} = \frac{1}{\pi} \int^{\infty}_0 f(y) \left( \frac{1}{x-y} + \frac{1}{x+y} \right) \D y.
\]
\end{thm}
Before we begin, recall the Riemann-Lebesgue lemma:
\begin{lem}[Theorem 11.6, \cite{apostol}]
Assume that $f \in L(I).$ Then, for each real $\beta,$ we have 
\[\lim_{\alpha\to\infty} \int_I f(t) \sin(\alpha t + \beta) \D t = 0.\]
\end{lem}
\begin{proof}[Proof of Theorem 1]
Consider
\[ 
(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \}.
\]
For generality, we consider $(\mathcal{F}^k_s)^{-1} \{ G(k) \},$ where $G$ is a function of $k$ defined on $k\geq 0.$ Expanding the integral, we obtain:
\begin{align*}
(\mathcal{F}^k_s)^{-1} \{ G(k) \} &= \int^{\infty}_0 \sin(kx) G(k) \D k \\
&= \frac{1}{2i} \int^{\infty}_0 (e^{ikx} - e^{-ikx}) G(k) \D k \\
&= \frac{1}{2i} \left[ \int^{\infty}_0 e^{ikx} G(k) \D k - \int^{\infty}_0 e^{-ikx} G(k) \D k\right] \\
&= \frac{1}{2i} \left[ \int^{\infty}_0 e^{ikx} G(k) \D k + \int^{-\infty}_0 e^{ikx} G(-k) \D k\right] &\text{(apply $k \mapsto - k$ in the 2nd term)} \\
&= \frac{1}{2i} \left[ \int^{\infty}_0 e^{ikx} G(k) \D k + \int_{-\infty}^0 e^{ikx} (-G(-k)) \D k\right],
\end{align*}
where $-G(-k)$ is an odd extension to $k<0$. Now, observe the following:
\begin{align*}
\frac{2}{\pi} \int^{\infty}_0 \cos(kx) f(x) \D x &=\frac{1}{\pi} \int^{\infty}_0 (e^{ikx} + e^{-ikx}) f(x) \D x \\
&= \frac{1}{\pi} \left[ \int^{\infty}_0 e^{ikx} f(x) \D x + \int^{\infty}_0 e^{-ikx} f(x) \D x \right] \\
&= \frac{1}{\pi} \left[ -\int^{-\infty}_0 e^{-ikx} f(-x) \D x  + \int^{\infty}_0 e^{-ikx} f(x) \D x  \right] &\text{(apply $x \mapsto - x$ in the 1st term)} \\
&= \frac{1}{\pi} \left[ \int_{-\infty}^0 e^{-ikx} f(-x) \D x  + \int^{\infty}_0 e^{-ikx} f(x) \D x \right] \\
&= \frac{1}{\pi} \int_{-\infty}^\infty e^{-ikx} F(x) \D x, 
\end{align*}
where we used an even extension to $x<0$ and defined
\[ 
F(x) = \begin{cases} f(x) & x>0 \\ f(-x) & x<0 \end{cases}.
\]
For $k>0,$ we have
\begin{equation}\label{G(k)}
G(k) = \mathcal{F}^k_c \{ f \} = \frac{2}{\pi} \int^{\infty}_0 \cos(kx) f(x) \D x = \frac{1}{\pi} \int_{-\infty}^\infty e^{-ikx} F(x) \D x.
\end{equation}
For $k<0,$ we have 
\begin{equation}\label{-G(-k)}
-G(- k) = - \mathcal{F}^{-k}_c \{ f \}  = -\frac{2}{\pi} \int^{\infty}_0 \cos(-kx) f(x) \D x =-\frac{2}{\pi} \int^{\infty}_0 \cos(kx) f(x) \D x = - \frac{1}{\pi} \int_{-\infty}^\infty e^{-ikx} F(x) \D x, 
\end{equation}
since cosine is an even function. Thus, using \eqref{G(k)} and \eqref{-G(-k)}, we obtain
\begin{align}
(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \} &= \frac{1}{2i} \left[ \int^{\infty}_0 e^{ikx} \mathcal{F}^k_c \{ f \} \D k + \int_{-\infty}^0 e^{ikx} (-\mathcal{F}^(-k)_c \{ f \}) \D k\right] \nonumber \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 e^{ikx}  \int_{-\infty}^\infty e^{-iky} F(y) \D y \D k - \int_{-\infty}^0 e^{ikx} \int_{-\infty}^\infty e^{-iky} F(y) \D y \D k\right] \nonumber \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 e^{ikx} \int_{-\infty}^\infty e^{ik(x-y)} F(y) \D y \D k - \int_{-\infty}^0 \int_{-\infty}^\infty e^{ik(x-y)} F(y) \D y \D k\right]. \label{expFF}
\end{align}
Let
\begin{align*}
V(k) &= \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y = -V(-k), \\
U(k) &= \int_{-\infty}^\infty \cos(k(x-y)) F(y) \D y = U(-k),
\end{align*}
so that $V$ is odd and $U$ is even. This allows to rewrite \eqref{expFF} as:
\begin{align*}
(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \} &= \frac{1}{2\pi i} \left[ \int^{\infty}_0 e^{ikx} \int_{-\infty}^\infty e^{ik(x-y)} F(y) \D y \D k - \int_{-\infty}^0 \int_{-\infty}^\infty e^{ik(x-y)} F(y) \D y \D k\right] \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 U(k) +i V(k) \D k - \int_{-\infty}^0 U(k) + i V(k) \D k\right] \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 U(k) +i V(k) \D k + \int_{\infty}^0 U(-k) + i V(-k) \D k\right] \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 U(k) +i V(k) \D k + \int^{\infty}_0 -U(-k) + i (-V(-k)) \D k\right] \\
&= \frac{1}{2\pi i} \left[ \int^{\infty}_0 U(k) +i V(k) \D k + \int^{\infty}_0 -U(k) + i V(k) \D k\right] \\
&= \frac{1}{\pi } \int^{\infty}_0 V(k) \D k,
\end{align*}
where on the third last line, we flipped the bounds of integration and brought the minus sign inside the integral, and on the second last line, we used that $U$ is even and $V$ is odd. Thus, we obtain 
\[ 
(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \} = \frac{1}{\pi } \int^{\infty}_0 V(k) \D k =  \frac{1}{\pi} \int^{\infty}_0 \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y \D k.
\]
Note that the integral in $k$ is an improper integral, so
\[
\int^{\infty}_0 \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y \D k = \lim_{\alpha \to \infty} \int^{\alpha}_0 \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y \D k.
\]
Now, interchanging the order of integration, we have 
\begin{align*}
\int^{\alpha}_0 \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y \D k &= \int_{-\infty}^\infty F(y) \int^{\alpha}_0  \sin(k(x-y)) \D k  \D y \\
&= \int_{-\infty}^\infty F(y) \left[ - \frac{\cos(k(x-y))}{x-y} \mid^\alpha_0 \right] \D y \\
&= \int_{-\infty}^\infty F(y) \left[ \frac{1}{x-y} - \frac{\cos(\alpha(x-y))}{x-y} \right] \D y \\
&= \int_{-\infty}^\infty F(y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y.
\end{align*}
The interchange is justified, since sine is bounded and differentiable on $\RR.$ Finally, we use the Riemann-Lebesgue lemma to deal with the last term:
\begin{align*}
\int_{-\infty}^\infty F(y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y &= \int_0^\infty f(y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y + \int_{-\infty}^0 f(-y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y \\
&= \int_0^\infty f(y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y - \int_{\infty}^0 f(y)  \frac{1 - \cos(\alpha(x+y))}{x+y} \D y \\
&= \int_0^\infty f(y)  \frac{1 - \cos(\alpha(x-y))}{x-y} \D y + \int^{\infty}_0 f(y)  \frac{1 - \cos(\alpha(x+y))}{x+y} \D y \\ 
&= \int_0^\infty f(y)  \frac{1}{x-y} \D y - \int_0^\infty f(y) \frac{\cos(\alpha(x-y))}{x-y} \D y \\
&+ \int^{\infty}_0 f(y) \frac{1}{x+y} \D y - \int^{\infty}_0 f(y) \frac{\cos(\alpha(x+y))}{x+y} \D y.
\end{align*}
As $\alpha \to \infty,$ the terms 
\[ \int_0^\infty f(y) \frac{\cos(\alpha(x-y))}{x-y} \D y, \qquad \int^{\infty}_0 f(y) \frac{\cos(\alpha(x+y))}{x+y} \D y \to 0\]
by the Riemann-Lebesgue lemma with $\beta = \pi/2$, so that 
\[ 
\int_{-\infty}^\infty F(y) \frac{1 - \cos(\alpha(x-y))}{x-y} \D y = \int_0^\infty f(y) \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y. 
\]
Thus, 
\[ (\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ f \} \} = \frac{1}{\pi} \int^{\infty}_0 \int_{-\infty}^\infty \sin(k(x-y)) F(y) \D y \D k = \frac{1}{\pi} \int_0^\infty f(y) \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y. \]
The proof is complete.
\end{proof}
\rmk{Note that the integral 
\[ \frac{1}{\pi} \int_0^\infty f(y) \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y = \]
looks like a convolution-type transform. In fact, the term with $1/(x-y)$ is pretty much the Hilbert transform, but on a half-line.
}

The theorem yields 
\[ \partial_x(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ \partial_t \left( \eta \int^{x}_0\eta_{t} \D x' \right)\} \}
= \partial_x \left( \frac{1}{\pi} \int_0^\infty \partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right)  \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y \right). \]
For generality, let $f(y) = \partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right).$ Note the following:
\begin{align*} 
\partial_x \left( \frac{1}{\pi} \int_0^\infty f(y) \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y \right) &= \frac{1}{\pi} \int_0^\infty f(y) \partial_x \left[ \frac{1}{x-y} + \frac{1}{x+y} \right] \D y \\
&= - \frac{1}{\pi} \int_0^\infty f(y)  \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y,
\end{align*}
so that
\begin{equation}\label{SingIntegral}
\partial_x(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ \partial_t \left( \eta \int^{x}_0\eta_{t} \D x' \right)\} \} = - \frac{1}{\pi} \int_0^\infty \partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y.
\end{equation}
As can be seen, the integral \eqref{SingIntegral} is singular whenever $x = y$ or $x = -y,$ over $y.$ To deal with this issue, one may need to use a Residue theorem. To conclude, the surface expression on a half-line becomes:
\begin{align*}
 \eta_{tt} - \eta_{xx} &= \mu^2 \left( \frac{1}{3} \eta_{xxxx}  + \partial_x(\mathcal{F}^k_s)^{-1} \{ \mathcal{F}^k_c \{ \partial_t \left( \eta \int^{x}_0\eta_{t} \D x' \right)\} \} + \frac{1}{2} \partial^2_x\left(\int^{x}_0\eta_{t} \D x' \right)^2\right) \\
 &= \mu^2 \left( \frac{1}{3} \eta_{xxxx}  - \frac{1}{\pi} \int_0^\infty \partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y + \frac{1}{2} \partial^2_x\left(\int^{x}_0\eta_{t} \D x' \right)^2\right) . 
\end{align*}

\section{Time stepping and finite differences: the half line}
On the half line, the equation for the surface elevation is given by:
\begin{equation}\label{srfcexpHL}
\eta_{tt} = \eta_{xx} + \mu^2 \left( \frac{1}{3} \eta_{xxxx}  - \frac{1}{\pi} \int_0^\infty \partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y + \frac{1}{2} \partial^2_x\left(\int^{x}_0\eta_{t} \D x' \right)^2\right) 
\end{equation}
To do time stepping, introduce
\begin{equation}\label{UexpHL}
u = \eta_t.
\end{equation}
Also, note that 
\[ 
\frac{1}{2}\partial_x^2 \left(\int^{x}_{0} \eta_t \D x' \right)^2 = \eta_t^2 + \eta_{tx} \int^x_{0}\eta_t \D x' = u^2 + u_{x} \int^x_{0}u \D x',
\]
and 
\[ 
\partial_t \left( \eta \int^{y}_0\eta_{t} \D y' \right)  = \eta_t \int^x_{0} \eta_t \D x' + \eta(\eta_x - \eta_x(0)) = u\int^x_{0} u\D x' + \eta(\eta_x - \eta_x(0)).
\]
Then, combining \eqref{UexpHL} and \eqref{srfcexpHL}, we obtain a two-dimensional system:
\begin{equation}\label{systemeq1HL}
  \partial_t \begin{bmatrix} u \\ \eta \end{bmatrix} =
  \begin{bmatrix} 
  \eta_{xx} +  \mu^2\left( \frac{1}{3} \eta_{xxxx} + u^2 + u_{x} \int^x_{0}u \D x' - \frac{1}{\pi} \int^{\infty}_0 u\int^x_{0} u\D x' + \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y \right) \\
  u \end{bmatrix}.
\end{equation}
Now, consider \eqref{srfcexpHL} on a finite interval $[a,b],$ and let partition the interval into $n+1$ points $\{ x_k\}^n_{k=0},$ with $x_0 = a$ and $x_n = b.$ Note that we need to pick the partition such that 
\[ 
\int^{\infty}_0 u\int^x_{0} u\D x' + \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y \approx \int^{x_n}_{x_0} u\int^x_{0} u\D x' + \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y.
\]
We proceed to forward Euler time stepping. First, observe that
\begin{align*}
u_t(x_k, t_j) &= \frac{u(x_k, t_{j+1}) - u(x_k, t_j)}{\DT} = f_1(\eta, u, t) &&\implies u(x_k, t_{j+1}) = u(x_k, t_j) + \DT f_1(\eta, u, t) \\
\eta_t(x_k, t_j) &= \frac{\eta(x_k, t_{j+1}) - \eta(x_k, t_j)}{\DT} = f_2(\eta, u, t) &&\implies \eta(x_k, t_{j+1}) =  \eta(x_k, t_j)+ \DT f_2(\eta, u, t), 
\end{align*}
where 
\begin{align*}
f_1(\eta, u, t) &= \eta_{xx} + \mu^2 \left(\frac{1}{3} \eta_{xxxx} + u^2 + u_{x} \int^x_{0}u \D x' - \frac{1}{\pi} \int^{\infty}_0 u\int^x_{0} u\D x' + \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x-y)^2} + \frac{1}{(x+y)^2} \right] \D y \right) \\
f_2(\eta, u, t) &= u(x_k, t_j).
\end{align*}
Observe that the highest order derivative is 4, so we need to use five-point stencils. In particular, we use five point midpoint stencil for $x_2, \ldots, x_{n-2},$ and five point, one-sided stencils at $x_0, x_1, x_{n-1}, x_n.$ First, consider the system for $x_2, \ldots, x_{n-2}:$
\begin{align*}
f_1(\eta(x_k, t_j), &u(x_k, t_j), t) = \eta(x_k, t_j)_{xx} + \frac{\mu^2}{3} \eta(x_k, t_j)_{xxxx} \\
&+ \mu^2 \left( u^2(x_k) + u_{x}(x_k) \int^{x_k}_{0}u \D x' - \frac{1}{\pi} \int^{x_n}_0 u\int^y_{0} u\D x' + \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y \right),
\end{align*}
where we have separated the linear and nonlinear terms. The only difference between this system and the whole-line system is the non-linear term; in other words, we can reuse our prior work on the linear term, and only deal with the non-linear term. Let 
\[ 
C_k = u^2(x_k) + u_{x}(x_k) \int^{x_k}_{0}u \D x' - \frac{1}{\pi} \int^{x_n}_0 \left(u\int^y_{0} u\D x' + \eta(\eta_x - \eta_x(0))\right) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y,
\]
and let $\mathcal{C}$ be the column vector of $C_k;$ thus, $\mathcal{C}$ represents the non-linear part of the system. To discretise $C_k,$ note that
\begin{align*}
\int^{x_k}_{0}u \D x' &= \frac{\DX}{2} \sum^{k-1}_{i=0} u(x_{i+1}) + u(x_i) \\
\int^{x_n}_0 u\int^y_{0} u\D x'  \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y &= \sum^{n-1}_{i=0} \int^{x_{i+1}}_{x_i} \left(u\int^y_{0} u\D x' \right) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y \\
&= \frac{\DX}{2} \sum^{n-1}_{i=0} u(x_{i+1})\int^{x_{i+1}}_{0} u\D x'  \left[ \frac{1}{(x_k-x_{i+1})^2} + \frac{1}{(x_k+x_{i+1})^2} \right] + u(x_{i}) \int^{x_{i}}_{0} u\D x' \left[ \frac{1}{(x_k-x_{i})^2} + \frac{1}{(x_k+x_{i})^2} \right] \\
&= \frac{\DX}{2} \sum^{n-1}_{i=0} \frac{\DX}{2} u(x_{i+1}) \left(\sum^{i}_{j=0} u(x_j)+u(x_{j+1}) \right) \left[ \frac{1}{(x_k-x_{i+1})^2} + \frac{1}{(x_k+x_{i+1})^2} \right] \\
&+ \frac{\DX}{2}u(x_{i}) \left(\sum^{i-1}_{j=0} u(x_j)+u(x_{j+1}) \right)\left[ \frac{1}{(x_k-x_{i})^2} + \frac{1}{(x_k+x_{i})^2} \right] \\
\int^{x_n}_0 \eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y &=  \sum^{n-1}_{i=0} \int^{x_{i+1}}_{x_i}\eta(\eta_x - \eta_x(0)) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y \\
&= \frac{\DX}{2} \sum^{n-1}_{i=0} \eta(x_{i+1})(\eta_x(x_{i+1}) - \eta_x(0)) \left[ \frac{1}{(x_k-x_{i+1})^2} + \frac{1}{(x_k+x_{i+1})^2} \right] + \eta(x_{i})(\eta_x(x_{i}) - \eta_x(0)) \left[ \frac{1}{(x_k-x_{i})^2} + \frac{1}{(x_k+x_{i})^2} \right]. 
\end{align*}
Therefore, we obtain that 
\begin{align*}
C_k &= u^2(x_k) + u_{x}(x_k) \int^{x_k}_{0}u \D x' - \frac{1}{\pi} \int^{x_n}_0 \left(u\int^y_{0} u\D x' + \eta(\eta_x - \eta_x(0))\right) \left[ \frac{1}{(x_k-y)^2} + \frac{1}{(x_k+y)^2} \right] \D y \\
&= u^2(x_k) + \frac{\DX}{2}  u_{x}(x_k) \sum^{k-1}_{i=0} u(x_{i+1}) + u(x_i) \\
&-\frac{1}{\pi} \frac{\DX}{2} \sum^{n-1}_{i=0} \left(\frac{\DX}{2} u(x_{i+1}) \left(\sum^{i}_{j=0} u(x_j)+u(x_{j+1}) \right) +\eta(x_{i+1})(\eta_x(x_{i+1}) - \eta_x(0)) \right) \left[ \frac{1}{(x_k-x_{i+1})^2} + \frac{1}{(x_k+x_{i+1})^2} \right] \\
&+ \left( \frac{\DX}{2}u(x_{i}) \left(\sum^{i-1}_{j=0} u(x_j)+u(x_{j+1}) \right) + \eta(x_{i})(\eta_x(x_{i}) - \eta_x(0))\right) \left[ \frac{1}{(x_k-x_{i})^2} + \frac{1}{(x_k+x_{i})^2} \right],
\end{align*}
where the expressions for derivatives depend on the point $x_k.$ Let 
\[ 
F_i = \frac{\DX}{2}u(x_{i}) \left(\sum^{i-1}_{j=0} u(x_j)+u(x_{j+1}) \right) + \eta(x_{i})(\eta_x(x_{i}) - \eta_x(0)), \qquad i = 0, \ldots n,
\] 
which we will store as an array. This simplification, we obtain 
\begin{align*}
C_k &= u^2(x_k) + \frac{\DX}{2}  u_{x}(x_k) \sum^{k-1}_{i=0} u(x_{i+1}) + u(x_i) -\frac{\DX}{2\pi} \sum^{n-1}_{i=0} F_{i+1} \left[ \frac{1}{(x_k-x_{i+1})^2} + \frac{1}{(x_k+x_{i+1})^2} \right] + F_{i} \left[ \frac{1}{(x_k-x_{i})^2} + \frac{1}{(x_k+x_{i})^2} \right],
\end{align*}
With this in mind, we obtain the finite differences system:
\begin{align*}
\begin{bmatrix}
u(x_0, t_{j+1}) \\
u(x_1, t_{j+1}) \\
u(x_2, t_{j+1}) \\
\vdots \\
u(x_{n-2}, t_{j+1}) \\
u(x_{n-1}, t_{j+1}) \\
u(x_n, t_{j+1}) 
\end{bmatrix} 
&= 
\begin{bmatrix}
u(x_0, t_{j}) \\
u(x_1, t_{j}) \\
u(x_2, t_{j}) \\
\vdots \\
u(x_{n-2}, t_{j}) \\
u(x_{n-1}, t_{j}) \\
u(x_n, t_{j}) 
\end{bmatrix} 
+ \DT 
\begin{bmatrix}
f_1(\eta(x_0, t_j), u(x_0, t_j), t)\\
f_1(\eta(x_1, t_j), u(x_1, t_j), t) \\
 f_1(\eta(x_2, t_j), u(x_2, t_j), t) \\
\vdots \\
f_1(\eta(x_{n-2}, t_j), u(x_{n-2}, t_j), t)\\
f_1(\eta(x_{n-1}, t_j), u(x_{n-1}, t_j), t) \\
f_1(\eta(x_n, t_j), u(x_n, t_j), t) 
\end{bmatrix} \\
&= 
\begin{bmatrix}
u(x_0, t_{j}) \\
u(x_1, t_{j}) \\
u(x_2, t_{j}) \\
\vdots \\
u(x_{n-2}, t_{j}) \\
u(x_{n-1}, t_{j}) \\
u(x_n, t_{j}) 
\end{bmatrix} 
+ \DT \mathcal{A} \begin{bmatrix}
\eta_0 \\
\eta_1 \\
\eta_2 \\
\vdots \\
\eta_{n-2} \\
\eta_{n-1} \\
\eta_{n}
\end{bmatrix}
+ \DT \mathcal{C}
\end{align*}


\bibliographystyle{amsplain}
{\small\bibliography{references}}

\end{document}
